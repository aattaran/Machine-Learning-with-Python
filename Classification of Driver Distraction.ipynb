{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Driver Distraction\n",
    "\n",
    "This project aims to develop a machine learning system that can detect and classify different distracted states of car drivers. The main approach is to apply deep convolutional neural networks (CNNs). We will explore and experiment various CNN architectures, leveraged pre-trained networks (learning transfer), psuedo labelling, and potentially an emsenbles of several models to find the best classification. Results of this project may be used to further research and applied to as a part of an on-car online monitoring system where computer will decide to take-over control of the car if the driver is distracted and poses a potential accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "[x.physical_device_desc for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, sys\n",
    "import numpy as np\n",
    "from numpy.random import random, permutation, randn, normal\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input,  GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.regularizers import l2,l1\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import bcolz\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "from shutil import move\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating validation set from traing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "PROJECT_DIR = current_dir\n",
    "path = current_dir+'/imgs/'\n",
    "test_path = path + 'test/' #We use all the test data\n",
    "train_path = path + '/train/'\n",
    "result_path = path + '/results/'\n",
    "valid_path = path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_modes = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "\n",
    "for i in class_modes:\n",
    "    print ('label {0} has {1:5d} images'.format(i,len([name for name in os.listdir(train_path+i) if os.path.isfile(os.path.join(train_path+i, name))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = float(0)\n",
    "for i in class_modes:\n",
    "    summ=summ+len([name for name in os.listdir(train_path+i) if os.path.isfile(os.path.join(train_path+i, name))])\n",
    "summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are around 2000 images for each categories. It is probably a good idea to move 20% of images (400 images for each categories) to validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd $train_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only run these Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in class_modes:\n",
    "    g = glob(label+\"/*.jpg\")\n",
    "    shuffle = np.random.permutation(g)\n",
    "    for i in range(400):\n",
    "        move(shuffle[i], valid_path+shuffle[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, \n",
    "                gen=image.ImageDataGenerator(), \n",
    "                shuffle=True,\n",
    "                batch_size=1, \n",
    "                target_size=(224, 224), \n",
    "                class_mode = \"categorical\"):\n",
    "    \n",
    "    return gen.flow_from_directory(path+dirname, \n",
    "                                   target_size, \n",
    "                                   class_mode=class_mode, \n",
    "                                   shuffle=shuffle, \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, titles=True, interp=False):\n",
    "\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "batches = get_batches(\"valid\", batch_size=6)\n",
    "imgs , labels = next(batches)\n",
    "#random images from validation \n",
    "plots(imgs, titles=labels, figsize=(20,15), rows =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(\"train\", batch_size=6)\n",
    "imgs , labels = next(batches)\n",
    "#random images from training \n",
    "plots(imgs, titles=labels, figsize=(20,15), rows =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the training and validation data\n",
    "\n",
    "## Only run these Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, target_size = (224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=20, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range (len(batches.classes))])\n",
    "\n",
    "\n",
    "train_data = get_data(\"train\")\n",
    "valid_data = get_date(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "save_array('results/train_data.dat', train_data)\n",
    "save_array('results/train_data.dat', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "\n",
    "(valid_classes, train_classes, valid_labels, train_labels, valid_filenames, train_filenames) = get_classes(path)\n",
    "valid_data = load_array(path+'results/valid_data.dat')\n",
    "train_data = load_array(path+'results/train_data.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiements\n",
    "\n",
    "##  2.1. Benchmark\n",
    "\n",
    "In this section I will use a fully connected network with no hidden layer, i.e., linear model. This is to provide a benchmark for other experiments developments.\n",
    "\n",
    "- I used batchnormalization right at the input layer to avoid any domination input values that could skew the output.\n",
    "- I activated the output with a softmax layer for 10 classes.\n",
    "- I will use 224x224 input shape, as the results we will have 1.5+ million parametters and easily overfitted with a linear model, hence, l2 regularization is used to minimize impact of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Linear_model = Sequential([\n",
    "        BatchNormalization(axis=-1, input_shape=(224,224,3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "Linear_model.compile(Adam(lr=0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "Linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
